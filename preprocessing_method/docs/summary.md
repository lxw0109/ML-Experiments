# 学习笔记
**数据的标准化(normalization)是将数据按比例缩放，使之落入一个小的特定区间。在某些比较和评价的指标处理中经常会用到，去除数据的单位限制，将其转化为无量纲的纯数值，便于不同单位或量级的指标能够进行比较和加权。其中最典型的就是数据的归一化处理，即将数据统一映射到[0,1]区间上。**  
1. 为什么要归一化？维基百科给出的解释：
 * 归一化后加快了梯度下降求最优解的速度
 * 归一化有可能提高精度  
  一些分类器需要计算样本之间的距离(如欧氏距离)，例如KNN。如果一个特征值域范围非常大，那么距离计算就主要取决于这个特征，从而与实际情况相悖(比如这时实际情况是值域范围小的特征更重要)
 * 深度学习中数据归一化可以防止模型梯度爆炸

 **References:**  
 + [归一化方法 Normalization Method](https://www.cnblogs.com/sddai/p/6250094.html)
 + [数据标准化/归一化normalization](https://blog.csdn.net/pipisorry/article/details/52247379)

2. 在进行数据分析的时候，什么情况下需要对数据进行标准化处理?  
 主要看模型是否具有**伸缩不变性**。有些模型在各个维度进行不均匀伸缩后，最优解与原来不等价，例如SVM。对于这样的模型，除非本来各维数据的分布范围就比较接近，否则必须进行标准化，以免模型参数被分布范围较大或较小的数据dominate。有些模型在各个维度进行不均匀伸缩后，最优解与原来等价，例如logistic regression。对于这样的模型，是否标准化理论上不会改变最优解。但是，由于实际求解往往使用迭代算法，如果目标函数的形状太“扁”，迭代算法可能收敛得很慢甚至不收敛。所以对于具有伸缩不变性的模型，最好也进行数据标准化。  

 **References:**  
 [在进行数据分析的时候，什么情况下需要对数据进行标准化处理?](https://www.zhihu.com/question/30038463/answer/50491149)

3. 常用的标准化方法  
 **1). max-min(Min-Max Normalization)**  
 也称为离差标准化，是对原始数据的线性变换，使结果值映射到[0, 1]之间。转换函数如下：
 ```
 x = (x - min) / (max - min)
 ```
 **tips:**  
  + 适用于本来就分布在有限范围内的数据
  + 这种归一化方法比较适用在数值比较集中的情况。但是，如果max和min不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定，实际使用中可以用经验常量值来替代max和min。而且当有新数据加入时，可能导致max和min的变化，需要重新定义
  + 如果想要将数据映射到[-1, 1]，则将转换函数换成`x = (x - mean) / (max - min)`, 其中mean是要标准化的数据的均值. 另一种简单的解决方法是[0, 1]公式 * 2 - 1得到的范围就是[-1, 1]了

 **2). z-score标准化**  
 **tips:**
  + 适用于分布没有明显边界的情况，受outlier影响也较小 
  + 这种方法给予原始数据的均值μ和标准差σ进行数据的标准化。经过处理的数据符合标准正态分布，即均值为0，标准差为1. 为什么z-score 标准化后的数据标准差为1? x-μ只改变均值，标准差不变，所以均值变为0. (x-μ)/σ只会使标准差除以σ倍，所以标准差变为1.
 转化函数如下:
 ```
 x* = (x - μ ) / σ
 ```
 其中μ为所有样本数据的均值，σ为所有样本数据的标准差。z-score标准化方法适用于属性的最大值和最小值未知的情况，或有超出取值范围的离群数据的情况。该种归一化方式要求原始数据的分布可以近似为高斯分布，否则归一化的效果会变得很糟糕。  
 
 **总结:**  
 上面有两种方法，那么到底什么情况使用哪一个呢?   
 在分类、聚类算法中，需要使用距离来度量相似性的时候, 或者使用PCA技术进行降维的时候，z-score normalization表现更好。  
 在不涉及距离度量、协方差计算、数据不符合正态分布的时候，可以使用Min-Max Normalization方法或其他归一化方法。比如图像处理中，将RGB图像转换为灰度图像后将其值限定在[0, 255]的范围。
